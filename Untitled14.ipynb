{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc955482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Icon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1da34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1=\"I am Atharva Joshi. I like to draw. Drawings are a very interesting tool to express your emotions. Using different colors in your drawing makes it more attractive and better. Drawings are very good in case of mental issues. \"\n",
    "string2=\"I am why you want to know. I like to draw. Drawings are a very interesting tool to express your emotions. Using different colors in your drawing makes it more attractive and better. Drawings are very good in case of mental issues. \"\n",
    "string3=\"Hello all good to see you all here . Hope you are doing well. I am also ok\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd568d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st part , tokenization\n",
    "token1=nltk.word_tokenize(string1)\n",
    "token2=nltk.word_tokenize(string2)\n",
    "token3=nltk.word_tokenize(string3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3354a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'Atharva',\n",
       " 'Joshi',\n",
       " '.',\n",
       " 'I',\n",
       " 'like',\n",
       " 'to',\n",
       " 'draw',\n",
       " '.',\n",
       " 'Drawings',\n",
       " 'are',\n",
       " 'a',\n",
       " 'very',\n",
       " 'interesting',\n",
       " 'tool',\n",
       " 'to',\n",
       " 'express',\n",
       " 'your',\n",
       " 'emotions',\n",
       " '.',\n",
       " 'Using',\n",
       " 'different',\n",
       " 'colors',\n",
       " 'in',\n",
       " 'your',\n",
       " 'drawing',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'and',\n",
       " 'better',\n",
       " '.',\n",
       " 'Drawings',\n",
       " 'are',\n",
       " 'very',\n",
       " 'good',\n",
       " 'in',\n",
       " 'case',\n",
       " 'of',\n",
       " 'mental',\n",
       " 'issues',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27738622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'why',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'know',\n",
       " '.',\n",
       " 'I',\n",
       " 'like',\n",
       " 'to',\n",
       " 'draw',\n",
       " '.',\n",
       " 'Drawings',\n",
       " 'are',\n",
       " 'a',\n",
       " 'very',\n",
       " 'interesting',\n",
       " 'tool',\n",
       " 'to',\n",
       " 'express',\n",
       " 'your',\n",
       " 'emotions',\n",
       " '.',\n",
       " 'Using',\n",
       " 'different',\n",
       " 'colors',\n",
       " 'in',\n",
       " 'your',\n",
       " 'drawing',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'and',\n",
       " 'better',\n",
       " '.',\n",
       " 'Drawings',\n",
       " 'are',\n",
       " 'very',\n",
       " 'good',\n",
       " 'in',\n",
       " 'case',\n",
       " 'of',\n",
       " 'mental',\n",
       " 'issues',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505d02d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'all',\n",
       " 'good',\n",
       " 'to',\n",
       " 'see',\n",
       " 'you',\n",
       " 'all',\n",
       " 'here',\n",
       " '.',\n",
       " 'Hope',\n",
       " 'you',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'well',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'also',\n",
       " 'ok']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84c2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Icon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd part , stop words removal\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae136591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenised list\n",
    "l=[token1,token2,token3]\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e280fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "133a30a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['atharva',\n",
       "  'joshi',\n",
       "  '.',\n",
       "  'like',\n",
       "  'draw',\n",
       "  '.',\n",
       "  'drawings',\n",
       "  'interesting',\n",
       "  'tool',\n",
       "  'express',\n",
       "  'emotions',\n",
       "  '.',\n",
       "  'using',\n",
       "  'different',\n",
       "  'colors',\n",
       "  'drawing',\n",
       "  'makes',\n",
       "  'attractive',\n",
       "  'better',\n",
       "  '.',\n",
       "  'drawings',\n",
       "  'good',\n",
       "  'case',\n",
       "  'mental',\n",
       "  'issues',\n",
       "  '.'],\n",
       " ['want',\n",
       "  'know',\n",
       "  '.',\n",
       "  'like',\n",
       "  'draw',\n",
       "  '.',\n",
       "  'drawings',\n",
       "  'interesting',\n",
       "  'tool',\n",
       "  'express',\n",
       "  'emotions',\n",
       "  '.',\n",
       "  'using',\n",
       "  'different',\n",
       "  'colors',\n",
       "  'drawing',\n",
       "  'makes',\n",
       "  'attractive',\n",
       "  'better',\n",
       "  '.',\n",
       "  'drawings',\n",
       "  'good',\n",
       "  'case',\n",
       "  'mental',\n",
       "  'issues',\n",
       "  '.'],\n",
       " ['hello', 'good', 'see', '.', 'hope', 'well', '.', 'also', 'ok']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all the words from the strings or docs which are present in stopwords list\n",
    "cleaned_tokens=[]\n",
    "for x in l:\n",
    "    temp=[]\n",
    "    for i in x:\n",
    "        if i.lower() not in stop_words:\n",
    "            temp.append(i.lower())\n",
    "    cleaned_tokens.append(temp)\n",
    "cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24982731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 - stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0fdcbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i am atharva joshi . i like to draw . draw are a veri interest tool to express your emot . use differ color in your draw make it more attract and better . draw are veri good in case of mental issu .', 'i am whi you want to know . i like to draw . draw are a veri interest tool to express your emot . use differ color in your draw make it more attract and better . draw are veri good in case of mental issu .', 'hello all good to see you all here . hope you are do well . i am also ok']\n"
     ]
    }
   ],
   "source": [
    "stemmed_sentences=[]\n",
    "for x in l:\n",
    "    stemmed=[]\n",
    "    for word in x:\n",
    "        stemmed.append(stemmer.stem(word))\n",
    "    stemmed_sentences.append((' ').join(stemmed))\n",
    "print(stemmed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f2830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Icon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part 4 - lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48277454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Atharva Joshi . I like to draw . Drawings are a very interesting tool to express your emotion . Using different color in your drawing make it more attractive and better . Drawings are very good in case of mental issue .',\n",
       " 'I am why you want to know . I like to draw . Drawings are a very interesting tool to express your emotion . Using different color in your drawing make it more attractive and better . Drawings are very good in case of mental issue .',\n",
       " 'Hello all good to see you all here . Hope you are doing well . I am also ok']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentences=[]\n",
    "for x in l:\n",
    "    lemmatized=[]\n",
    "    for word in x:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    lemmatized_sentences.append((' ').join(lemmatized))\n",
    "lemmatized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c5e201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Icon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 5 - pos tagging\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b33b502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('Atharva', 'NNP'),\n",
       "  ('Joshi', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('like', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('draw', 'VB'),\n",
       "  ('.', '.'),\n",
       "  ('Drawings', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('very', 'RB'),\n",
       "  ('interesting', 'JJ'),\n",
       "  ('tool', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('express', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('emotions', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('Using', 'VBG'),\n",
       "  ('different', 'JJ'),\n",
       "  ('colors', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('drawing', 'NN'),\n",
       "  ('makes', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('more', 'RBR'),\n",
       "  ('attractive', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('better', 'RBR'),\n",
       "  ('.', '.'),\n",
       "  ('Drawings', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('in', 'IN'),\n",
       "  ('case', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('mental', 'JJ'),\n",
       "  ('issues', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('why', 'WRB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('want', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('know', 'VB'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('like', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('draw', 'VB'),\n",
       "  ('.', '.'),\n",
       "  ('Drawings', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('very', 'RB'),\n",
       "  ('interesting', 'JJ'),\n",
       "  ('tool', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('express', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('emotions', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('Using', 'VBG'),\n",
       "  ('different', 'JJ'),\n",
       "  ('colors', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('drawing', 'NN'),\n",
       "  ('makes', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('more', 'RBR'),\n",
       "  ('attractive', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('better', 'RBR'),\n",
       "  ('.', '.'),\n",
       "  ('Drawings', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('in', 'IN'),\n",
       "  ('case', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('mental', 'JJ'),\n",
       "  ('issues', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [('Hello', 'NNP'),\n",
       "  ('all', 'DT'),\n",
       "  ('good', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('see', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('here', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('Hope', 'NNP'),\n",
       "  ('you', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('doing', 'VBG'),\n",
       "  ('well', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('also', 'RB'),\n",
       "  ('ok', 'JJ')]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged=[]\n",
    "# instead of word it requires word of tokens\n",
    "for x in l:\n",
    "    tagged.append(pos_tag(x))\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5338e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove full stops from the cleaned tokens as it is required for calculating TF,IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f0ac0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[]\n",
    "for x in cleaned_tokens:\n",
    "    temp=[]\n",
    "    for i in x:\n",
    "        if i!='.':\n",
    "            temp.append(i)\n",
    "    l1.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73230437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atharva': 0.047619047619047616, 'joshi': 0.047619047619047616, 'like': 0.047619047619047616, 'draw': 0.047619047619047616, 'drawings': 0.09523809523809523, 'interesting': 0.047619047619047616, 'tool': 0.047619047619047616, 'express': 0.047619047619047616, 'emotions': 0.047619047619047616, 'using': 0.047619047619047616, 'different': 0.047619047619047616, 'colors': 0.047619047619047616, 'drawing': 0.047619047619047616, 'makes': 0.047619047619047616, 'attractive': 0.047619047619047616, 'better': 0.047619047619047616, 'good': 0.047619047619047616, 'case': 0.047619047619047616, 'mental': 0.047619047619047616, 'issues': 0.047619047619047616}\n",
      "{'want': 0.047619047619047616, 'know': 0.047619047619047616, 'like': 0.047619047619047616, 'draw': 0.047619047619047616, 'drawings': 0.09523809523809523, 'interesting': 0.047619047619047616, 'tool': 0.047619047619047616, 'express': 0.047619047619047616, 'emotions': 0.047619047619047616, 'using': 0.047619047619047616, 'different': 0.047619047619047616, 'colors': 0.047619047619047616, 'drawing': 0.047619047619047616, 'makes': 0.047619047619047616, 'attractive': 0.047619047619047616, 'better': 0.047619047619047616, 'good': 0.047619047619047616, 'case': 0.047619047619047616, 'mental': 0.047619047619047616, 'issues': 0.047619047619047616}\n",
      "{'hello': 0.14285714285714285, 'good': 0.14285714285714285, 'see': 0.14285714285714285, 'hope': 0.14285714285714285, 'well': 0.14285714285714285, 'also': 0.14285714285714285, 'ok': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "tf1={} # map for 1st string\n",
    "tf2={} # map for 2nd string\n",
    "tf3={} # map for 3rd string\n",
    "setg=set() # for not getting duplicated words, to reduce time complexity\n",
    "for i in l1[0]:\n",
    "    if i in tf1:\n",
    "        tf1[i]+=1\n",
    "    else:\n",
    "        tf1[i]=1\n",
    "    setg.add(i)\n",
    "for i in l1[1]:\n",
    "    if i in tf2:\n",
    "        tf2[i]+=1\n",
    "    else:\n",
    "        tf2[i]=1\n",
    "    setg.add(i)\n",
    "for i in l1[2]:\n",
    "    if i in tf3:\n",
    "        tf3[i]+=1\n",
    "    else:\n",
    "        tf3[i]=1\n",
    "    setg.add(i)\n",
    "for key,value in tf1.items():\n",
    "    tf1[key]=value/len(l1[0])\n",
    "for key,value in tf2.items():\n",
    "    tf2[key]=value/len(l1[1])\n",
    "for key,value in tf3.items():\n",
    "    tf3[key]=value/len(l1[2])\n",
    "print(tf1)\n",
    "print(tf2)\n",
    "print(tf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c149ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'express', 'also', 'joshi', 'drawings', 'makes', 'know', 'emotions', 'colors', 'case', 'see', 'mental', 'attractive', 'using', 'interesting', 'tool', 'better', 'hello', 'ok', 'drawing', 'draw', 'like', 'good', 'atharva', 'want', 'issues', 'well', 'different', 'hope'}\n"
     ]
    }
   ],
   "source": [
    "print(setg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a349f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF\n",
      "express     0.4054651081081644\n",
      "also     1.0986122886681098\n",
      "joshi     1.0986122886681098\n",
      "drawings     0.4054651081081644\n",
      "makes     0.4054651081081644\n",
      "know     1.0986122886681098\n",
      "emotions     0.4054651081081644\n",
      "colors     0.4054651081081644\n",
      "case     0.4054651081081644\n",
      "see     1.0986122886681098\n",
      "mental     0.4054651081081644\n",
      "attractive     0.4054651081081644\n",
      "using     0.4054651081081644\n",
      "interesting     0.4054651081081644\n",
      "tool     0.4054651081081644\n",
      "better     0.4054651081081644\n",
      "hello     1.0986122886681098\n",
      "ok     1.0986122886681098\n",
      "drawing     0.4054651081081644\n",
      "draw     0.4054651081081644\n",
      "like     0.4054651081081644\n",
      "good     0.0\n",
      "atharva     1.0986122886681098\n",
      "want     1.0986122886681098\n",
      "issues     0.4054651081081644\n",
      "well     1.0986122886681098\n",
      "different     0.4054651081081644\n",
      "hope     1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(\"IDF\")\n",
    "lis={}\n",
    "for x in setg:\n",
    "    cnt=0\n",
    "    if x in tf1.keys():\n",
    "        cnt+=1\n",
    "    if x in tf2.keys():\n",
    "        cnt+=1\n",
    "    if x in tf3.keys():\n",
    "        cnt+=1\n",
    "    lis[x]=math.log(3/cnt)\n",
    "    print(x,\"   \",math.log(3/cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a21308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'express': 0.4054651081081644, 'also': 1.0986122886681098, 'joshi': 1.0986122886681098, 'drawings': 0.4054651081081644, 'makes': 0.4054651081081644, 'know': 1.0986122886681098, 'emotions': 0.4054651081081644, 'colors': 0.4054651081081644, 'case': 0.4054651081081644, 'see': 1.0986122886681098, 'mental': 0.4054651081081644, 'attractive': 0.4054651081081644, 'using': 0.4054651081081644, 'interesting': 0.4054651081081644, 'tool': 0.4054651081081644, 'better': 0.4054651081081644, 'hello': 1.0986122886681098, 'ok': 1.0986122886681098, 'drawing': 0.4054651081081644, 'draw': 0.4054651081081644, 'like': 0.4054651081081644, 'good': 0.0, 'atharva': 1.0986122886681098, 'want': 1.0986122886681098, 'issues': 0.4054651081081644, 'well': 1.0986122886681098, 'different': 0.4054651081081644, 'hope': 1.0986122886681098}\n"
     ]
    }
   ],
   "source": [
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92ad1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atharva     0.05231487088895761\n",
      "joshi     0.05231487088895761\n",
      "like     0.01930786229086497\n",
      "draw     0.01930786229086497\n",
      "drawings     0.03861572458172994\n",
      "interesting     0.01930786229086497\n",
      "tool     0.01930786229086497\n",
      "express     0.01930786229086497\n",
      "emotions     0.01930786229086497\n",
      "using     0.01930786229086497\n",
      "different     0.01930786229086497\n",
      "colors     0.01930786229086497\n",
      "drawing     0.01930786229086497\n",
      "makes     0.01930786229086497\n",
      "attractive     0.01930786229086497\n",
      "better     0.01930786229086497\n",
      "good     0.0\n",
      "case     0.01930786229086497\n",
      "mental     0.01930786229086497\n",
      "issues     0.01930786229086497\n",
      "\n",
      "\n",
      "want     0.05231487088895761\n",
      "know     0.05231487088895761\n",
      "like     0.01930786229086497\n",
      "draw     0.01930786229086497\n",
      "drawings     0.03861572458172994\n",
      "interesting     0.01930786229086497\n",
      "tool     0.01930786229086497\n",
      "express     0.01930786229086497\n",
      "emotions     0.01930786229086497\n",
      "using     0.01930786229086497\n",
      "different     0.01930786229086497\n",
      "colors     0.01930786229086497\n",
      "drawing     0.01930786229086497\n",
      "makes     0.01930786229086497\n",
      "attractive     0.01930786229086497\n",
      "better     0.01930786229086497\n",
      "good     0.0\n",
      "case     0.01930786229086497\n",
      "mental     0.01930786229086497\n",
      "issues     0.01930786229086497\n",
      "\n",
      "\n",
      "hello    0.15694461266687282\n",
      "good    0.0\n",
      "see    0.15694461266687282\n",
      "hope    0.15694461266687282\n",
      "well    0.15694461266687282\n",
      "also    0.15694461266687282\n",
      "ok    0.15694461266687282\n"
     ]
    }
   ],
   "source": [
    "# TF IDF\n",
    "for x in tf1:\n",
    "    print(x,\"   \",tf1[x]*lis[x])\n",
    "print()\n",
    "print()\n",
    "for x in tf2:\n",
    "    print(x,\"   \",tf2[x]*lis[x])\n",
    "    \n",
    "print()\n",
    "print()\n",
    "for x in tf3:\n",
    "    print(x,\"  \",tf3[x]*lis[x])\n",
    "\n",
    "# more the value, more important the word is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16d246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
